{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "JvRJIwTfCBqu",
      "metadata": {
        "id": "JvRJIwTfCBqu"
      },
      "source": [
        "# Islamic Fatwa Hybrid Search — HOML End-to-End\n",
        "**TF-IDF + AraBERT · MRR@10 · Multi-Dataset · Flask + ngrok UI**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "I6XvS2DgCBqv",
      "metadata": {
        "id": "I6XvS2DgCBqv"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "I7fD3tb_k7KB",
      "metadata": {
        "id": "I7fD3tb_k7KB"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mN-b6AP5CBqv",
      "metadata": {
        "collapsed": true,
        "id": "mN-b6AP5CBqv"
      },
      "outputs": [],
      "source": [
        "!pip install kagglehub sentence-transformers scikit-learn \\\n",
        "           pyarabic matplotlib seaborn scipy flask pyngrok flask-cors -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pebk5OMjCBqv",
      "metadata": {
        "id": "pebk5OMjCBqv"
      },
      "outputs": [],
      "source": [
        "import os, re, math, pickle, shutil, threading, time\n",
        "import numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt, seaborn as sns, torch\n",
        "import pyarabic.araby as araby\n",
        "\n",
        "from sklearn.base                    import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline                import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise        import cosine_similarity\n",
        "from sklearn.model_selection         import train_test_split\n",
        "from scipy.sparse                    import save_npz\n",
        "from sentence_transformers           import SentenceTransformer, InputExample, losses\n",
        "from torch.utils.data                import DataLoader\n",
        "import kagglehub\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "for d in [\"data/raw\",\"data/processed\",\"models/tfidf\",\"models/bert\",\"reports/figures\",\"templates\"]:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "print(f\"✅ Imports ready  |  device={DEVICE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nJRbP1_uCBqw",
      "metadata": {
        "id": "nJRbP1_uCBqw"
      },
      "source": [
        "## Dataset Registry — Switch Datasets Here\n",
        "\n",
        "Change `ACTIVE_DATASET` to any key below, then **Run All**.  \n",
        "All downstream cells adapt automatically.\n",
        "\n",
        "| Key | Source | Rows | Columns |\n",
        "|-----|--------|------|---------|\n",
        "| `islamweb` | `abdallahelsaadany/fatawa` (IslamWeb) | ~83K | `title, ques, ans` |\n",
        "| `50k_mixed` | `hazemmosalah/50k-islamic-fatwa-q-and-a-dataset-arabic` | ~51K | `question, answer` |\n",
        "| `binbaz` | `a5medashraf/bin-baz-fatwas-dataset` | ~7K | `Questions, Answers` |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VKhDVUKvCBqw",
      "metadata": {
        "id": "VKhDVUKvCBqw"
      },
      "outputs": [],
      "source": [
        "# ══════════════════════════════════════════════════\n",
        "# switch datasets\n",
        "ACTIVE_DATASET = \"islamweb\"\n",
        "# ══════════════════════════════════════════════════\n",
        "\n",
        "DATASETS = {\n",
        "    \"islamweb\": {\n",
        "        \"kaggle_id\"  : \"abdallahelsaadany/fatawa\",\n",
        "        \"col_title\"  : \"title\",     # optional title column (or None)\n",
        "        \"col_q\"      : \"ques\",      # question column\n",
        "        \"col_a\"      : \"ans\",       # answer column\n",
        "        \"label\"      : \"IslamWeb Fatawa (~83K)\",\n",
        "    },\n",
        "    \"50k_mixed\": {\n",
        "        \"kaggle_id\"  : \"hazemmosalah/50k-islamic-fatwa-q-and-a-dataset-arabic\",\n",
        "        \"col_title\"  : None,\n",
        "        \"col_q\"      : \"question\",\n",
        "        \"col_a\"      : \"answer\",\n",
        "        \"label\"      : \"50K Mixed Fatawa (Bin Baz + IslamQA + IslamWeb)\",\n",
        "    },\n",
        "    \"binbaz\": {\n",
        "        \"kaggle_id\"  : \"a5medashraf/bin-baz-fatwas-dataset\",\n",
        "        \"col_title\"  : None,\n",
        "        \"col_q\"      : \"Questions\",\n",
        "        \"col_a\"      : \"Answers\",\n",
        "        \"label\"      : \"Bin Baz Fatwas (~7K)\",\n",
        "    },\n",
        "}\n",
        "\n",
        "DS   = DATASETS[ACTIVE_DATASET]\n",
        "CFG  = dict(\n",
        "    sample_n  = 15_000,  test_size = 0.10,  seed      = 42,\n",
        "    min_q     = 5,       min_a     = 10,\n",
        "    tfidf_q_max=20_000,  tfidf_d_max=15_000,\n",
        "    ngram     = (1,4),   min_df    = 2,\n",
        "    tfidf_q_w = 0.25,    tfidf_d_w = 0.75,\n",
        "    hybrid_t  = 0.50,    hybrid_b  = 0.50,\n",
        "    bert_name = \"aubmindlab/bert-base-arabertv02\",\n",
        "    bert_batch= 128,     ft_batch  = 16,\n",
        "    ft_epochs = 1,       ft_n      = 2_000, warmup = 0.10,\n",
        "    top_k     = 3,       mrr_k     = 10,    mrr_n  = 500,\n",
        ")\n",
        "\n",
        "print(f\"Active dataset : {DS['label']}\")\n",
        "print(f\"   Columns       : title={DS['col_title']}  q={DS['col_q']}  a={DS['col_a']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BMfMV6RGCBqw",
      "metadata": {
        "id": "BMfMV6RGCBqw"
      },
      "source": [
        "## Big Picture\n",
        "- **Task:** Arabic fatwa retrieval · **Metric:** MRR@10 on held-out test set\n",
        "- **Architecture:** 50% TF-IDF + 50% AraBERT cosine similarity\n",
        "- **Anti-leakage:** index built on `df_train` only; MRR measured on `df_test`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Vj7IAVoVCBqw",
      "metadata": {
        "id": "Vj7IAVoVCBqw"
      },
      "source": [
        "## Geting the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Pvuftl81CBqw",
      "metadata": {
        "collapsed": true,
        "id": "Pvuftl81CBqw"
      },
      "outputs": [],
      "source": [
        "def load_dataset(ds_cfg):\n",
        "    \"\"\"Download from Kaggle, normalise to standard columns: question, answer, title.\"\"\"\n",
        "    path     = kagglehub.dataset_download(\"abdallahelsaadany/fatawa\")\n",
        "    csv_file = next(\n",
        "        os.path.join(r,f) for r,_,fs in os.walk(path) for f in fs if f.endswith(\".csv\")\n",
        "    )\n",
        "    df = pd.read_csv(csv_file)\n",
        "    df = df.rename(columns={\n",
        "        ds_cfg[\"col_q\"]: \"question\",\n",
        "        ds_cfg[\"col_a\"]: \"answer\",\n",
        "    })\n",
        "    if ds_cfg[\"col_title\"] and ds_cfg[\"col_title\"] in df.columns:\n",
        "        df = df.rename(columns={ds_cfg[\"col_title\"]: \"title\"})\n",
        "    else:\n",
        "        df[\"title\"] = \"\"\n",
        "\n",
        "    df = df[[\"question\",\"answer\",\"title\"]].copy()\n",
        "    df[\"question\"] = df[\"question\"].fillna(\"\")\n",
        "    df[\"answer\"]   = df[\"answer\"].fillna(\"\")\n",
        "    df[\"title\"]    = df[\"title\"].fillna(\"\")\n",
        "    return df\n",
        "\n",
        "df_raw = load_dataset(DS)\n",
        "print(f\"Loaded: {df_raw.shape}  from  [{DS['label']}]\")\n",
        "print(df_raw.head(3).to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ckpBxZLTCBqw",
      "metadata": {
        "id": "ckpBxZLTCBqw"
      },
      "source": [
        "## Explore the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "W0tggOB3CBqw",
      "metadata": {
        "id": "W0tggOB3CBqw"
      },
      "outputs": [],
      "source": [
        "eda = df_raw.assign(\n",
        "    q_chars = df_raw.question.str.len(),\n",
        "    a_chars = df_raw.answer.str.len(),\n",
        "    q_words = df_raw.question.str.split().str.len(),\n",
        "    a_words = df_raw.answer.str.split().str.len(),\n",
        ")\n",
        "print(eda[[\"q_chars\",\"a_chars\",\"q_words\",\"a_words\"]].describe().round(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ogIvv_3CBqw",
      "metadata": {
        "id": "7ogIvv_3CBqw"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(13, 7))\n",
        "fig.suptitle(f\"EDA — {DS['label']}\", fontsize=13, fontweight=\"bold\")\n",
        "\n",
        "for ax,(col,title,color,clip) in zip(axes.flat, [\n",
        "    (\"q_chars\",\"Question Char Length\",\"steelblue\",    500),\n",
        "    (\"a_chars\",\"Answer Char Length\",  \"darkorange\",  2000),\n",
        "    (\"q_words\",\"Question Word Count\", \"seagreen\",     100),\n",
        "    (\"a_words\",\"Answer Word Count\",   \"mediumpurple\", 400),\n",
        "]):\n",
        "    ax.hist(eda[col].clip(0,clip), bins=50, color=color, edgecolor=\"white\")\n",
        "    ax.set_title(title)\n",
        "    ax.axvline(eda[col].median(), color=\"red\", ls=\"--\", label=f\"Median={eda[col].median():.0f}\")\n",
        "    ax.legend(fontsize=8)\n",
        "\n",
        "plt.tight_layout()\n",
        "fig_path = f\"reports/figures/eda_{ACTIVE_DATASET}.png\"\n",
        "plt.savefig(fig_path, dpi=150); plt.show(); print(f\"Saved → {fig_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3hEKrR3hCBqx",
      "metadata": {
        "id": "3hEKrR3hCBqx"
      },
      "source": [
        "## Prepare the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NnPpYpfICBqx",
      "metadata": {
        "id": "NnPpYpfICBqx"
      },
      "outputs": [],
      "source": [
        "class ArabicCleaner(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None): return self\n",
        "    def transform(self, X):   return [self._c(t) for t in X]\n",
        "    @staticmethod\n",
        "    def _c(t):\n",
        "        if pd.isna(t) or not str(t).strip(): return \"\"\n",
        "        t = araby.strip_tashkeel(araby.strip_tatweel(str(t)))\n",
        "        return \" \".join(re.sub(r\"[^\\u0600-\\u06FF\\s]\",\" \",t).split())\n",
        "\n",
        "class DFCleaner(BaseEstimator, TransformerMixin):\n",
        "    _c = ArabicCleaner()\n",
        "    def fit(self, X, y=None): return self\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        X[\"question_clean\"] = self._c.transform(X[\"question\"])\n",
        "        X[\"answer_clean\"]   = self._c.transform(X[\"answer\"])\n",
        "        X[\"title_clean\"]    = self._c.transform(X[\"title\"])\n",
        "        # doc = title + question (x3 weight) + answer  for richer TF-IDF\n",
        "        X[\"doc\"] = (X[\"title_clean\"]+\" \") + (X[\"question_clean\"]+\" \")*3 + X[\"answer_clean\"]\n",
        "        return X[\n",
        "            (X[\"question_clean\"].str.len() > CFG[\"min_q\"]) &\n",
        "            (X[\"answer_clean\"].str.len()   > CFG[\"min_a\"])\n",
        "        ].reset_index(drop=True)\n",
        "\n",
        "df_clean = DFCleaner().fit_transform(df_raw)\n",
        "if len(df_clean) > CFG[\"sample_n\"]:\n",
        "    df_clean = df_clean.sample(CFG[\"sample_n\"], random_state=CFG[\"seed\"]).reset_index(drop=True)\n",
        "\n",
        "df_train, df_test = train_test_split(\n",
        "    df_clean, test_size=CFG[\"test_size\"], random_state=CFG[\"seed\"], shuffle=True\n",
        ")\n",
        "df_train = df_train.reset_index(drop=True)\n",
        "df_test  = df_test.reset_index(drop=True)\n",
        "\n",
        "df_train.to_csv(f\"data/processed/{ACTIVE_DATASET}_train.csv\", index=False)\n",
        "df_test.to_csv( f\"data/processed/{ACTIVE_DATASET}_test.csv\",  index=False)\n",
        "print(f\"Train: {len(df_train):,}  |  Test: {len(df_test):,}   (no leakage)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5PHD0aGCBqx",
      "metadata": {
        "id": "c5PHD0aGCBqx"
      },
      "source": [
        "## Train & Evaluate (Baseline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xs91qyPqCBqx",
      "metadata": {
        "id": "xs91qyPqCBqx"
      },
      "outputs": [],
      "source": [
        "# TF-IDF\n",
        "q_vec = TfidfVectorizer(max_features=CFG[\"tfidf_q_max\"], ngram_range=CFG[\"ngram\"], min_df=CFG[\"min_df\"])\n",
        "dv    = TfidfVectorizer(max_features=CFG[\"tfidf_d_max\"], ngram_range=CFG[\"ngram\"], min_df=CFG[\"min_df\"])\n",
        "q_mat = q_vec.fit_transform(df_train[\"question_clean\"])\n",
        "d_mat = dv.fit_transform(df_train[\"doc\"])\n",
        "print(f\"TF-IDF  Q:{q_mat.shape}  Doc:{d_mat.shape}\")\n",
        "\n",
        "tfidf_dir = f\"models/tfidf/{ACTIVE_DATASET}\"\n",
        "os.makedirs(tfidf_dir, exist_ok=True)\n",
        "for name,obj in [(\"q_vec\",q_vec),(\"dv\",dv)]:\n",
        "    with open(f\"{tfidf_dir}/{name}.pkl\",\"wb\") as f: pickle.dump(obj,f)\n",
        "save_npz(f\"{tfidf_dir}/q_mat.npz\", q_mat)\n",
        "save_npz(f\"{tfidf_dir}/d_mat.npz\", d_mat)\n",
        "\n",
        "# BERT baseline embeddings — TRAIN corpus only\n",
        "bert = SentenceTransformer(CFG[\"bert_name\"], device=DEVICE)\n",
        "emb  = bert.encode(df_train[\"question_clean\"].tolist(),\n",
        "                   batch_size=CFG[\"bert_batch\"], show_progress_bar=True, device=DEVICE)\n",
        "bert_dir = f\"models/bert/{ACTIVE_DATASET}\"\n",
        "os.makedirs(bert_dir, exist_ok=True)\n",
        "np.save(f\"{bert_dir}/embeddings.npy\", emb)\n",
        "print(f\"Embeddings: {emb.shape}  \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "As4btQkiCBqx",
      "metadata": {
        "id": "As4btQkiCBqx"
      },
      "outputs": [],
      "source": [
        "def _norm(s):\n",
        "    mn,mx = s.min(),s.max()\n",
        "    return np.zeros_like(s) if mx-mn<1e-8 else (s-mn)/(mx-mn+1e-8)\n",
        "\n",
        "_ac = ArabicCleaner()\n",
        "\n",
        "class Engine:\n",
        "    def __init__(self, df, q_vec, q_mat, dv, d_mat, bert, emb, device):\n",
        "        self.df=df.reset_index(drop=True); self.q_vec=q_vec; self.q_mat=q_mat\n",
        "        self.dv=dv; self.d_mat=d_mat; self.bert=bert; self.emb=emb; self.device=device\n",
        "\n",
        "    def search(self, q, top_k=3):\n",
        "        c = _ac._c(q)\n",
        "        if len(c)<3: return [{\"error\":\"Query too short\"}]\n",
        "        tfidf = (CFG[\"tfidf_q_w\"]*cosine_similarity(self.q_vec.transform([c]),self.q_mat).flatten() +\n",
        "                 CFG[\"tfidf_d_w\"]*cosine_similarity(self.dv.transform([c]),   self.d_mat).flatten())\n",
        "        bs    = cosine_similarity(self.bert.encode([c],device=self.device), self.emb).flatten()\n",
        "        score = CFG[\"hybrid_t\"]*_norm(tfidf) + CFG[\"hybrid_b\"]*_norm(bs)\n",
        "        return [{\"question\" : self.df.iloc[i][\"question\"],\n",
        "                 \"answer\"   : self.df.iloc[i][\"answer\"],\n",
        "                 \"title\"    : self.df.iloc[i].get(\"title\",\"\"),\n",
        "                 \"confidence\":f\"{score[i]*100:.1f}%\",\n",
        "                 \"tfidf\"    :f\"{_norm(tfidf)[i]*100:.1f}%\",\n",
        "                 \"bert\"     :f\"{_norm(bs)[i]*100:.1f}%\",\n",
        "                 \"_idx\"     : int(i)}\n",
        "                for i in score.argsort()[-top_k:][::-1]]\n",
        "\n",
        "def mrr(df_corpus, df_eval, engine, k=10, n=500, seed=99):\n",
        "    \"\"\"MRR@K — evaluated on held-out df_eval (no leakage).\"\"\"\n",
        "    ans_idx = {r[\"answer_clean\"][:80]:i for i,r in df_corpus.iterrows()}\n",
        "    sample  = df_eval.sample(min(n,len(df_eval)), random_state=seed)\n",
        "    rrs, hits = [], 0\n",
        "    for _,row in sample.iterrows():\n",
        "        gt = ans_idx.get(row[\"answer_clean\"][:80])\n",
        "        rr = 0.0\n",
        "        if gt is not None:\n",
        "            for rank,res in enumerate(engine.search(row[\"question_clean\"],k),1):\n",
        "                if res[\"_idx\"]==gt: rr=1/rank; hits+=1; break\n",
        "        rrs.append(rr)\n",
        "    n_=len(rrs); print(f\"  Hits@{k}: {hits}/{n_} ({hits/n_*100:.1f}%)\")\n",
        "    return float(np.mean(rrs))\n",
        "\n",
        "eng = Engine(df_train, q_vec, q_mat, dv, d_mat, bert, emb, DEVICE)\n",
        "print(f\"Baseline MRR@{CFG['mrr_k']} — {DS['label']}\")\n",
        "mrr_before = mrr(df_train, df_test, eng, CFG[\"mrr_k\"], CFG[\"mrr_n\"])\n",
        "print(f\"\\nBaseline MRR@{CFG['mrr_k']} = {mrr_before:.4f}  ({mrr_before*100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1M2sDxFpCBqx",
      "metadata": {
        "id": "1M2sDxFpCBqx"
      },
      "source": [
        "## Fine-Tune AraBERT (MNRL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "put05N63CBqx",
      "metadata": {
        "id": "put05N63CBqx"
      },
      "outputs": [],
      "source": [
        "examples = [InputExample(texts=[r[\"question_clean\"],r[\"answer_clean\"]])\n",
        "             for _,r in df_train.sample(CFG[\"ft_n\"],random_state=CFG[\"seed\"]).iterrows()]\n",
        "loader   = DataLoader(examples, shuffle=True, batch_size=CFG[\"ft_batch\"])\n",
        "warmup   = math.ceil(len(loader)*CFG[\"ft_epochs\"]*CFG[\"warmup\"])\n",
        "ft_path  = f\"models/bert/{ACTIVE_DATASET}/finetuned\"\n",
        "\n",
        "print(f\"Fine-tuning  n={CFG['ft_n']}  batch={CFG['ft_batch']}  warmup={warmup}\")\n",
        "bert.fit(train_objectives=[(loader, losses.MultipleNegativesRankingLoss(bert))],\n",
        "         epochs=CFG[\"ft_epochs\"], warmup_steps=warmup,\n",
        "         show_progress_bar=True, output_path=ft_path)\n",
        "\n",
        "emb = bert.encode(df_train[\"question_clean\"].tolist(),\n",
        "                  batch_size=CFG[\"bert_batch\"], show_progress_bar=True, device=DEVICE)\n",
        "np.save(f\"models/bert/{ACTIVE_DATASET}/embeddings.npy\", emb)\n",
        "\n",
        "eng_ft     = Engine(df_train, q_vec, q_mat, dv, d_mat, bert, emb, DEVICE)\n",
        "mrr_after  = mrr(df_train, df_test, eng_ft, CFG[\"mrr_k\"], CFG[\"mrr_n\"])\n",
        "print(f\"\\n Fine-Tuned MRR@{CFG['mrr_k']} = {mrr_after:.4f}  ({mrr_after*100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VCCfR5bHCBqx",
      "metadata": {
        "id": "VCCfR5bHCBqx"
      },
      "source": [
        "## Present the Solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LSzI1LcPCBqx",
      "metadata": {
        "id": "LSzI1LcPCBqx"
      },
      "outputs": [],
      "source": [
        "delta = mrr_after - mrr_before\n",
        "print(\"=\"*55)\n",
        "print(f\"  Dataset    : {DS['label']}\")\n",
        "print(f\"  Baseline   MRR@{CFG['mrr_k']} : {mrr_before:.4f}  ({mrr_before*100:.2f}%)\")\n",
        "print(f\"  Fine-Tuned MRR@{CFG['mrr_k']} : {mrr_after:.4f}  ({mrr_after*100:.2f}%)\")\n",
        "print(f\"  Δ MRR                 : {delta:+.4f}  ({'✅ improvement' if delta>0 else '❌ no improvement'})\")\n",
        "print(\"=\"*55)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5,4))\n",
        "bars = ax.bar([\"Baseline\",\"Fine-Tuned\"],[mrr_before,mrr_after],\n",
        "              color=[\"steelblue\",\"seagreen\"], width=0.4, edgecolor=\"white\")\n",
        "ax.set_ylim(0,1); ax.set_ylabel(f\"MRR@{CFG['mrr_k']}\")\n",
        "ax.set_title(f\"MRR@{CFG['mrr_k']} — {DS['label']}\", fontweight=\"bold\", fontsize=9)\n",
        "for b,v in zip(bars,[mrr_before,mrr_after]):\n",
        "    ax.text(b.get_x()+b.get_width()/2, v+0.02, f\"{v:.4f}\", ha=\"center\", fontweight=\"bold\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"reports/figures/mrr_{ACTIVE_DATASET}.png\", dpi=150); plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TnHLCCv2CBqx",
      "metadata": {
        "id": "TnHLCCv2CBqx"
      },
      "outputs": [],
      "source": [
        "for q in [\"حكم صلاة الجمعة\",\"ما هو الزكاة\",\"هل يجوز الصيام في السفر\"]:\n",
        "    print(f\"\\nSearch {q}\")\n",
        "    for r in eng_ft.search(q, CFG[\"top_k\"]):\n",
        "        title = f'[{r[\"title\"][:40]}] ' if r[\"title\"] else \"\"\n",
        "        print(f\"  {title}[{r['confidence']}] TF:{r['tfidf']} BERT:{r['bert']}\")\n",
        "        print(f\"  Q: {r['question'][:80]}...\")\n",
        "        print(f\"  A: {r['answer'][:100]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "z8Zs7n6QCBqx",
      "metadata": {
        "id": "z8Zs7n6QCBqx"
      },
      "source": [
        "## Launch: Flask + ngrok UI\n",
        "\n",
        "*  Laptop: paste URL into `laptop_server.py` → `python laptop_server.py` → open `http://localhost:8080`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "H83vwZ6fCBqx",
      "metadata": {
        "id": "H83vwZ6fCBqx"
      },
      "outputs": [],
      "source": [
        "# Cell A — Write laptop_server.py (run this on your LAPTOP)\n",
        "srv = '''from flask import Flask, render_template, request, jsonify\n",
        "import requests\n",
        "\n",
        "app = Flask(__name__, template_folder=\"templates\")\n",
        "COLAB_URL = \"\"\n",
        "\n",
        "@app.route(\"/\")\n",
        "def home(): return render_template(\"index.html\")\n",
        "\n",
        "@app.route(\"/ask\", methods=[\"POST\"])\n",
        "def ask():\n",
        "    d = request.get_json()\n",
        "    q = d.get(\"question\",\"\").strip()\n",
        "    if not q: return jsonify({\"error\":\"Empty question\"}), 400\n",
        "    try:\n",
        "        r = requests.post(f\"{COLAB_URL}/ask\",\n",
        "                          json={\"question\":q,\"top_k\":d.get(\"top_k\",3)}, timeout=60)\n",
        "        return jsonify(r.json()) if r.ok else jsonify({\"error\":f\"Colab {r.status_code}\"}), 500\n",
        "    except requests.ConnectionError:\n",
        "        return jsonify({\"error\":\"Cannot reach Colab — is Cell B running?\"}), 500\n",
        "    except requests.Timeout:\n",
        "        return jsonify({\"error\":\"Colab timeout\"}), 500\n",
        "\n",
        "@app.route(\"/health\")\n",
        "def health():\n",
        "    try:\n",
        "        r = requests.get(f\"{COLAB_URL}/health\", timeout=5)\n",
        "        return jsonify({\"status\":\"connected\",\"colab\":r.json()}) if r.ok \\\n",
        "               else jsonify({\"status\":\"disconnected\"}), 500\n",
        "    except: return jsonify({\"status\":\"disconnected\"}), 500\n",
        "\n",
        "@app.route(\"/update_url\", methods=[\"POST\"])\n",
        "def update_url():\n",
        "    global COLAB_URL\n",
        "    COLAB_URL = request.get_json().get(\"url\",\"\").strip().rstrip(\"/\")\n",
        "    return jsonify({\"status\":\"ok\",\"url\":COLAB_URL})\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(f\"UI → http://localhost:8080  |  Colab: {COLAB_URL}\")\n",
        "    app.run(host=\"0.0.0.0\", port=8080, debug=True)\n",
        "'''\n",
        "with open(\"laptop_server.py\",\"w\") as f: f.write(srv)\n",
        "print(\" laptop_server.py written\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6OJBZ8zBCBqx",
      "metadata": {
        "id": "6OJBZ8zBCBqx"
      },
      "outputs": [],
      "source": [
        "# Cell A — Start Colab Flask API + ngrok\n",
        "import threading\n",
        "import time\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "from pyngrok import ngrok\n",
        "\n",
        "ngrok.kill()\n",
        "\n",
        "# https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "NGROK_TOKEN = \"\"\n",
        "ngrok.set_auth_token(NGROK_TOKEN)\n",
        "\n",
        "api = Flask(__name__)\n",
        "CORS(api)\n",
        "\n",
        "@api.route(\"/health\")\n",
        "def health():\n",
        "    return jsonify({\"status\":\"ok\", \"device\":DEVICE})\n",
        "\n",
        "@api.route(\"/ask\", methods=[\"POST\"])\n",
        "def ask():\n",
        "    d = request.get_json(force=True)\n",
        "    q = d.get(\"question\",\"\").strip()\n",
        "    if len(q)<2: return jsonify({\"error\":\"Query too short\"}), 400\n",
        "\n",
        "    # Assuming 'eng_ft' is your search engine object defined in a previous cell\n",
        "    raw = eng_ft.search(q, int(d.get(\"top_k\",3)))\n",
        "    return jsonify({\n",
        "        \"analysis\": {\"intent\":q},\n",
        "        \"results\" : [{\"id\":i+1, **r} for i,r in enumerate(raw)],\n",
        "    })\n",
        "PORT = 5001\n",
        "\n",
        "threading.Thread(target=lambda: api.run(host=\"0.0.0.0\", port=PORT,\n",
        "                                        use_reloader=False, debug=False),\n",
        "                 daemon=True).start()\n",
        "\n",
        "time.sleep(2)\n",
        "\n",
        "\n",
        "url = ngrok.connect(PORT).public_url\n",
        "print(f\"\\n Colab API live → {url}\")\n",
        "print(f\" 1. Edit laptop_server.py → COLAB_URL = '{url}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hK8Q4JdBCBqy",
      "metadata": {
        "collapsed": true,
        "id": "hK8Q4JdBCBqy"
      },
      "outputs": [],
      "source": [
        "# Smoke test\n",
        "import requests as req\n",
        "print(\"Health:\", req.get(\"http://localhost:5000/health\").json())\n",
        "r = req.post(\"http://localhost:5000/ask\",json={\"question\":\"حكم صلاة الجمعة\",\"top_k\":2}).json()\n",
        "for res in r.get(\"results\",[]):\n",
        "    print(f\"  [{res['confidence']}] {res['title'][:50] or res['question'][:50]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ieb5L06rCBqy",
      "metadata": {
        "id": "Ieb5L06rCBqy"
      },
      "outputs": [],
      "source": [
        "# Stop ngrok\n",
        "from pyngrok import ngrok; ngrok.kill(); print(\"Tunnel closed\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "generative_ai_disabled": true,
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
