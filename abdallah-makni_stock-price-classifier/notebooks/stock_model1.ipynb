{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4a8e2de",
   "metadata": {},
   "source": [
    "# Stock Market Direction Prediction – S&P 500\n",
    "\n",
    "## Project Overview\n",
    "The goal of this project is to predict the next-day direction of the S&P 500 index (Up or Down) using machine learning.\n",
    "\n",
    "Instead of predicting the exact price, the model predicts whether the market will go up (1) or down (0) based on historical closing prices.\n",
    "\n",
    "This is a binary classification problem applied to financial time-series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4e6d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96670c2d",
   "metadata": {},
   "source": [
    "## Data Collection\n",
    "\n",
    "The dataset used in this project is `SP500.csv`.\n",
    "\n",
    "It contains:\n",
    "- observation_date: The trading date\n",
    "- SP500: The closing price of the S&P 500 index\n",
    "\n",
    "The data is loaded using pandas and prepared for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70926d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Robust data path: works whether Jupyter is started from repo root or notebooks/\n",
    "candidate_paths = [Path('data/SP500.csv'), Path('../data/SP500.csv')]\n",
    "data_path = next((p for p in candidate_paths if p.exists()), None)\n",
    "if data_path is None:\n",
    "    raise FileNotFoundError('Could not find SP500.csv in data/ or ../data/')\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "print('Using data file:', data_path.resolve())\n",
    "\n",
    "date_col = df.columns[0]\n",
    "df[date_col] = pd.to_datetime(df[date_col])\n",
    "df = df.sort_values(date_col).reset_index(drop=True)\n",
    "if date_col != 'observation_date':\n",
    "    df = df.rename(columns={date_col: 'observation_date'})\n",
    "\n",
    "PREDICTION_HORIZON_DAYS = 5\ndf['Target'] = (df['SP500'].shift(-PREDICTION_HORIZON_DAYS) > df['SP500']).astype(int)\n",
    "\n",
    "df['ret_1'] = df['SP500'].pct_change(1, fill_method=None)\n",
    "df['ret_2'] = df['SP500'].pct_change(2, fill_method=None)\n",
    "df['ret_5'] = df['SP500'].pct_change(5, fill_method=None)\n",
    "df['ma_5'] = df['SP500'].rolling(5).mean()\n",
    "df['ma_10'] = df['SP500'].rolling(10).mean()\n",
    "df['ma_20'] = df['SP500'].rolling(20).mean()\n",
    "df['vol_5'] = df['ret_1'].rolling(5).std()\n",
    "df['momentum_5'] = df['SP500'] / df['SP500'].shift(5) - 1\n",
    "df['ma_ratio_5'] = df['SP500'] / df['ma_5'] - 1\n",
    "df['ma_ratio_10'] = df['SP500'] / df['ma_10'] - 1\n",
    "df['ma_ratio_20'] = df['SP500'] / df['ma_20'] - 1\n",
    "df['day_of_week'] = df['observation_date'].dt.dayofweek\n",
    "\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "feature_cols = ['ret_1','ret_2','ret_5','vol_5','momentum_5','ma_ratio_5','ma_ratio_10','ma_ratio_20','day_of_week']\n",
    "X = df[feature_cols]\n",
    "y = df['Target']\n",
    "\n",
    "print('Rows after feature engineering:', len(df))\n",
    "print('Date range:', df['observation_date'].min().date(), '->', df['observation_date'].max().date())\n",
    "print('Target mean (Up ratio):', round(y.mean(), 4))\n",
    "print('Features:', feature_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afbea31",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "1. The date column is converted to datetime format.\n",
    "2. The dataset is sorted chronologically.\n",
    "3. A new target column is created:\n",
    "   - Target = 1 if price after 5 days is higher\n",
    "   - Target = 0 if price after 5 days is lower\n",
    "4. The last row is removed because it has no next-day value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44544b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(len(df) * 0.8)\n",
    "\n",
    "X_train = X.iloc[:split]\n",
    "X_val   = X.iloc[split:]\n",
    "\n",
    "y_train = y.iloc[:split]\n",
    "y_val   = y.iloc[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7796239",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Feature (X):\n",
    "- Engineered technical indicators (returns, volatility, momentum, moving-average ratios, day of week)\n",
    "\n",
    "Target (y):\n",
    "- Binary direction (Up = 1, Down = 0)\n",
    "\n",
    "Only numerical features are used for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472390a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=3,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb0353b",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "\n",
    "The dataset is split chronologically:\n",
    "\n",
    "- 80% for training\n",
    "- 20% for validation\n",
    "\n",
    "We do not shuffle the data because this is time-series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2616ba37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_p = scaler.fit_transform(X_train)\n",
    "X_val_p   = scaler.transform(X_val)\n",
    "\n",
    "print(X_train_p.shape, X_val_p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d357869",
   "metadata": {},
   "source": [
    "## Data Scaling\n",
    "\n",
    "StandardScaler is used to normalize the feature values.\n",
    "\n",
    "Scaling improves model performance and ensures stable learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6fb315",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "The model used is XGBoost Classifier.\n",
    "\n",
    "Main parameters:\n",
    "- n_estimators = 300\n",
    "- max_depth = 3\n",
    "- learning_rate = 0.05\n",
    "- subsample = 0.8\n",
    "- colsample_bytree = 0.8\n",
    "\n",
    "XGBoost is chosen because it is powerful for classification problems and handles structured data efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d84531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "model = xgb.XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=3,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    eval_metric=\"logloss\"\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train_p,\n",
    "    y_train,\n",
    "    eval_set=[(X_val_p, y_val)],\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264e78f8",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "The model is trained using the training dataset.\n",
    "\n",
    "Validation data is used to evaluate performance during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94f9f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_p = scaler.fit_transform(X_train)\n",
    "X_val_p   = scaler.transform(X_val)\n",
    "\n",
    "print(X_train_p.shape, X_val_p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f47f95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "log_model = LogisticRegression(max_iter=2000, random_state=42)\n",
    "\n",
    "# Train\n",
    "log_model.fit(X_train_p, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_log = log_model.predict(X_val_p)\n",
    "\n",
    "# Accuracy\n",
    "acc_log = accuracy_score(y_val, y_pred_log)\n",
    "print(f\"Logistic Regression Accuracy: {int(acc_log*100)}%\")\n",
    "\n",
    "# ROC-AUC\n",
    "roc_log = roc_auc_score(y_val, log_model.predict_proba(X_val_p)[:,1])\n",
    "print(\"Logistic Regression ROC-AUC:\", roc_log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cd39b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train\n",
    "knn_model.fit(X_train_p, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_knn = knn_model.predict(X_val_p)\n",
    "\n",
    "# Accuracy\n",
    "acc_knn = accuracy_score(y_val, y_pred_knn)\n",
    "print(f\"KNN Accuracy: {int(acc_knn*100)}%\")\n",
    "\n",
    "# ROC-AUC\n",
    "roc_knn = roc_auc_score(y_val, knn_model.predict_proba(X_val_p)[:,1])\n",
    "print(\"KNN ROC-AUC:\", roc_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03fdba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train\n",
    "dt_model.fit(X_train_p, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_dt = dt_model.predict(X_val_p)\n",
    "\n",
    "# Accuracy\n",
    "acc_dt = accuracy_score(y_val, y_pred_dt)\n",
    "print(f\"Decision Tree Accuracy: {int(acc_dt*100)}%\")\n",
    "\n",
    "# ROC-AUC\n",
    "roc_dt = roc_auc_score(y_val, dt_model.predict_proba(X_val_p)[:,1])\n",
    "print(\"Decision Tree ROC-AUC:\", roc_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326047b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train\n",
    "rf_model.fit(X_train_p, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_rf = rf_model.predict(X_val_p)\n",
    "\n",
    "# Accuracy\n",
    "acc_rf = accuracy_score(y_val, y_pred_rf)\n",
    "print(f\"Random Forest Accuracy: {int(acc_rf*100)}%\")\n",
    "\n",
    "# ROC-AUC\n",
    "roc_rf = roc_auc_score(y_val, rf_model.predict_proba(X_val_p)[:,1])\n",
    "print(\"Random Forest ROC-AUC:\", roc_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42421974",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(probability=True, random_state=42)\n",
    "\n",
    "svm_model.fit(X_train_p, y_train)\n",
    "\n",
    "y_pred_svm = svm_model.predict(X_val_p)\n",
    "\n",
    "acc_svm = accuracy_score(y_val, y_pred_svm)\n",
    "print(f\"SVM Accuracy: {int(acc_svm*100)}%\")\n",
    "\n",
    "roc_svm = roc_auc_score(y_val, svm_model.predict_proba(X_val_p)[:,1])\n",
    "print(\"SVM ROC-AUC:\", roc_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a6cc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "nb_model.fit(X_train_p, y_train)\n",
    "\n",
    "y_pred_nb = nb_model.predict(X_val_p)\n",
    "\n",
    "acc_nb = accuracy_score(y_val, y_pred_nb)\n",
    "print(f\"Naive Bayes Accuracy: {int(acc_nb*100)}%\")\n",
    "\n",
    "roc_nb = roc_auc_score(y_val, nb_model.predict_proba(X_val_p)[:,1])\n",
    "print(\"Naive Bayes ROC-AUC:\", roc_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3968cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "gb_model.fit(X_train_p, y_train)\n",
    "\n",
    "y_pred_gb = gb_model.predict(X_val_p)\n",
    "\n",
    "acc_gb = accuracy_score(y_val, y_pred_gb)\n",
    "print(f\"Gradient Boosting Accuracy: {int(acc_gb*100)}%\")\n",
    "\n",
    "roc_gb = roc_auc_score(y_val, gb_model.predict_proba(X_val_p)[:,1])\n",
    "print(\"Gradient Boosting ROC-AUC:\", roc_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cd965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion(model, X_val, y_val, model_name):\n",
    "    \n",
    "    y_pred = model.predict(X_val)\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    \n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                                   display_labels=[\"Down\", \"Up\"])\n",
    "    \n",
    "    disp.plot(cmap=\"Blues\")\n",
    "    plt.title(f\"Confusion Matrix - {model_name}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735066c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion(log_model, X_val_p, y_val, \"Logistic Regression\")\n",
    "plot_confusion(knn_model, X_val_p, y_val, \"KNN\")\n",
    "plot_confusion(dt_model, X_val_p, y_val, \"Decision Tree\")\n",
    "plot_confusion(rf_model, X_val_p, y_val, \"Random Forest\")\n",
    "plot_confusion(svm_model, X_val_p, y_val, \"SVM\")\n",
    "plot_confusion(nb_model, X_val_p, y_val, \"Naive Bayes\")\n",
    "plot_confusion(gb_model, X_val_p, y_val, \"Gradient Boosting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b367b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    \"Model\": [\n",
    "        \"Logistic Regression\",\n",
    "        \"KNN\",\n",
    "        \"Decision Tree\",\n",
    "        \"Random Forest\",\n",
    "        \"SVM\",\n",
    "        \"Naive Bayes\",\n",
    "        \"Gradient Boosting\"\n",
    "    ],\n",
    "    \"Accuracy\": [\n",
    "        acc_log,\n",
    "        acc_knn,\n",
    "        acc_dt,\n",
    "        acc_rf,\n",
    "        acc_svm,\n",
    "        acc_nb,\n",
    "        acc_gb\n",
    "    ],\n",
    "    \"ROC-AUC\": [\n",
    "        roc_log,\n",
    "        roc_knn,\n",
    "        roc_dt,\n",
    "        roc_rf,\n",
    "        roc_svm,\n",
    "        roc_nb,\n",
    "        roc_gb\n",
    "    ]\n",
    "})\n",
    "\n",
    "comparison[\"Accuracy\"] = (comparison[\"Accuracy\"] * 100).round(0).astype(int)\ncomparison.sort_values(by=\"Accuracy\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e11b0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(comparison[\"Model\"], comparison[\"Accuracy\"])\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Model Accuracy Comparison (%)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9089fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = comparison.sort_values(by=\"Accuracy\", ascending=True)\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45326f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.barh(comparison[\"Model\"], comparison[\"Accuracy\"])\n",
    "\n",
    "plt.xlabel(\"Accuracy (%)\")\n",
    "plt.title(\"Model Comparison by Accuracy\")\n",
    "\n",
    "plt.xlim(0, 1)  # يخلي المقياس واضح من 0 إلى 1\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620dde52",
   "metadata": {},
   "source": [
    "## Final Comparison and Conclusion\n",
    "\n",
    "In this project, seven different classification models were trained to predict the S&P 500 market direction. The models were evaluated using Accuracy, ROC-AUC score, and Confusion Matrix.\n",
    "\n",
    "With engineered technical features and a time-based split, the best validation accuracy is around 61%. This is an improvement over the single-feature baseline.\n",
    "\n",
    "Among the tested models, the best performance was achieved by the model with the highest Accuracy and ROC-AUC score.\n",
    "\n",
    "These results highlight the high level of noise and uncertainty in financial markets. Future improvements could include using more advanced feature engineering, additional financial indicators, or deep learning models.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}